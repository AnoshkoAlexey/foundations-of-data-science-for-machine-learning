{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise: Using a Trained Model on New Data\n",
        "\n",
        "In Unit 3, we created a basic model that let us find the relationship between a dog's harness size and their boot size. We showed how this model could then be used to make a prediction about a new, previously unseen dog.\n",
        "\n",
        "It's common to build, train, then use a model while we are just learning about machine learning; but in the real world, we don't want to train the model _every time_ we want to make a prediction.\n",
        "\n",
        "Consider our avalanche-dog equipment store scenario:\n",
        "\n",
        "* We want to train the model just once, then load that model onto the server that runs our online store. \n",
        "* Although the model is _trained_ on a dataset we downloaded from the internet, we actually want to _use_ it to estimate the boot size of our customers' dogs who are not in this dataset! \n",
        "\n",
        "How can we do this?\n",
        "\n",
        "Here, we'll:\n",
        "\n",
        "1. Create a basic model\n",
        "2. Save it to disk\n",
        "3. Load it from disk\n",
        "4. Use it to make predictions about a dog who was not in the training dataset\n",
        "\n",
        "## Load the dataset\n",
        "\n",
        "Let's begin by opening the dataset from file."
      ],
      "metadata": {},
      "id": "e3e57e33"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas\n",
        "!pip install statsmodels\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\n",
        "!wget https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-boot-harness.csv\n",
        "\n",
        "# Load a file containing dog's boot and harness sizes\n",
        "data = pandas.read_csv('doggy-boot-harness.csv')\n",
        "\n",
        "# Print the first few rows\n",
        "data.head()\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: statsmodels in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (0.11.0)\nRequirement already satisfied: numpy>=1.14 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from statsmodels) (1.21.6)\nRequirement already satisfied: pandas>=0.21 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from statsmodels) (1.1.5)\nRequirement already satisfied: patsy>=0.5 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from statsmodels) (0.5.2)\nRequirement already satisfied: scipy>=1.0 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from statsmodels) (1.5.3)\nRequirement already satisfied: python-dateutil>=2.7.3 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas>=0.21->statsmodels) (2.8.2)\nRequirement already satisfied: pytz>=2017.2 in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from pandas>=0.21->statsmodels) (2022.1)\nRequirement already satisfied: six in /anaconda/envs/azureml_py38/lib/python3.8/site-packages (from patsy>=0.5->statsmodels) (1.16.0)\n--2022-12-19 21:29:26--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/graphing.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 21511 (21K) [text/plain]\nSaving to: ‘graphing.py.2’\n\ngraphing.py.2       100%[===================>]  21.01K  --.-KB/s    in 0s      \n\n2022-12-19 21:29:26 (63.7 MB/s) - ‘graphing.py.2’ saved [21511/21511]\n\n--2022-12-19 21:29:27--  https://raw.githubusercontent.com/MicrosoftDocs/mslearn-introduction-to-machine-learning/main/Data/doggy-boot-harness.csv\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 838 [text/plain]\nSaving to: ‘doggy-boot-harness.csv.2’\n\ndoggy-boot-harness. 100%[===================>]     838  --.-KB/s    in 0s      \n\n2022-12-19 21:29:27 (59.2 MB/s) - ‘doggy-boot-harness.csv.2’ saved [838/838]\n\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 1,
          "data": {
            "text/plain": "   boot_size  harness_size     sex  age_years\n0         39            58    male       12.0\n1         38            58    male        9.6\n2         37            52  female        8.6\n3         39            58    male       10.2\n4         38            57    male        7.8",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>boot_size</th>\n      <th>harness_size</th>\n      <th>sex</th>\n      <th>age_years</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>39</td>\n      <td>58</td>\n      <td>male</td>\n      <td>12.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>38</td>\n      <td>58</td>\n      <td>male</td>\n      <td>9.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37</td>\n      <td>52</td>\n      <td>female</td>\n      <td>8.6</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>39</td>\n      <td>58</td>\n      <td>male</td>\n      <td>10.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>38</td>\n      <td>57</td>\n      <td>male</td>\n      <td>7.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {},
      "id": "64366eb9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and train a model\n",
        "\n",
        "As we've done before, we'll create a simple Linear Regression model and train it on our dataset."
      ],
      "metadata": {},
      "id": "822fff6b"
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Fit a simple model that finds a linear relationship\n",
        "# between boot size and harness size, which we can use later\n",
        "# to predict a dog's boot size, given their harness size\n",
        "model = smf.ols(formula = \"boot_size ~ harness_size\", data = data).fit()\n",
        "\n",
        "print(\"Model trained!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model trained!\n"
        }
      ],
      "execution_count": 2,
      "metadata": {},
      "id": "978d5fe6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save and load a model\n",
        "\n",
        "Our model is ready to use, but we don't need it yet. Let's save it to disk."
      ],
      "metadata": {},
      "id": "5d355498"
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "model_filename = './avalanche_dog_boot_model.pkl'\n",
        "joblib.dump(model, model_filename)\n",
        "\n",
        "print(\"Model saved!\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Model saved!\n"
        }
      ],
      "execution_count": 3,
      "metadata": {},
      "id": "8f592dec"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading our model is just as easy:"
      ],
      "metadata": {},
      "id": "68ea0066"
    },
    {
      "cell_type": "code",
      "source": [
        "model_loaded = joblib.load(model_filename)\n",
        "\n",
        "print(\"We have loaded a model with the following parameters:\")\n",
        "print(model_loaded.params)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "We have loaded a model with the following parameters:\nIntercept       5.719110\nharness_size    0.585925\ndtype: float64\n"
        }
      ],
      "execution_count": 4,
      "metadata": {},
      "id": "9405a7d2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Put it together\n",
        "\n",
        "On our website, we'll want to take the harness of our customer's dog, then calculate their dog's boot size using the model that we've already trained.\n",
        "\n",
        "Let's put everything here together to make a function that loads the model from disk, then uses it to predict our customer's dog's boot size height."
      ],
      "metadata": {},
      "id": "b732e62b"
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's write a function that loads and uses our model\n",
        "def load_model_and_predict(harness_size):\n",
        "    '''\n",
        "    This function loads a pretrained model. It uses the model\n",
        "    with the customer's dog's harness size to predict the size of\n",
        "    boots that will fit that dog.\n",
        "\n",
        "    harness_size: The dog harness size, in cm \n",
        "    '''\n",
        "\n",
        "    # Load the model from file and print basic information about it\n",
        "    loaded_model = joblib.load(model_filename)\n",
        "\n",
        "    print(\"We've loaded a model with the following parameters:\")\n",
        "    print(loaded_model.params)\n",
        "\n",
        "    # Prepare data for the model\n",
        "    inputs = {\"harness_size\":[harness_size]} \n",
        "\n",
        "    # Use the model to make a prediction\n",
        "    predicted_boot_size = loaded_model.predict(inputs)[0]\n",
        "\n",
        "    return predicted_boot_size\n",
        "\n",
        "# Practice using our model\n",
        "predicted_boot_size = load_model_and_predict(45)\n",
        "\n",
        "print(\"Predicted dog boot size:\", predicted_boot_size)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "We've loaded a model with the following parameters:\nIntercept       5.719110\nharness_size    0.585925\ndtype: float64\nPredicted dog boot size: 32.08575356590478\n"
        }
      ],
      "execution_count": 6,
      "metadata": {},
      "id": "f0c9e8b2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Real world use \n",
        "\n",
        "We've done it; we can predict an avalanche dog's boot size based on the size of their harness. Our last step is to use this to warn people if they might be buying the wrong sized doggy boots. \n",
        "\n",
        "As an example, we'll make a function that accepts the harness size, the size of the boots selected, and returns a message for the customer. We would integrate this function into our online store."
      ],
      "metadata": {},
      "id": "cb3b0fc4"
    },
    {
      "cell_type": "code",
      "source": [
        "def check_size_of_boots(selected_harness_size, selected_boot_size):\n",
        "    '''\n",
        "    Calculates whether the customer has chosen a pair of doggy boots that \n",
        "    are a sensible size. This works by estimating the dog's actual boot \n",
        "    size from their harness size.\n",
        "\n",
        "    This returns a message for the customer that should be shown before\n",
        "    they complete their payment \n",
        "\n",
        "    selected_harness_size: The size of the harness the customer wants to buy\n",
        "    selected_boot_size: The size of the doggy boots the customer wants to buy\n",
        "    '''\n",
        "\n",
        "    # Estimate the customer's dog's boot size\n",
        "    estimated_boot_size = load_model_and_predict(selected_harness_size)\n",
        "\n",
        "    # Round to the nearest whole number because we don't sell partial sizes\n",
        "    estimated_boot_size = int(round(estimated_boot_size))\n",
        "\n",
        "    # Check if the boot size selected is appropriate\n",
        "    if selected_boot_size == estimated_boot_size:\n",
        "        # The selected boots are probably OK\n",
        "        return f\"Great choice! We think these boots will fit your avalanche dog well.\"\n",
        "\n",
        "    if selected_boot_size < estimated_boot_size:\n",
        "        # Selected boots might be too small \n",
        "        return \"The boots you have selected might be TOO SMALL for a dog as \"\\\n",
        "               f\"big as yours. We recommend a doggy boots size of {estimated_boot_size}.\"\n",
        "\n",
        "    if selected_boot_size > estimated_boot_size:\n",
        "        # Selected boots might be too big \n",
        "        return \"The boots you have selected might be TOO BIG for a dog as \"\\\n",
        "               f\"small as yours. We recommend a doggy boots size of {estimated_boot_size}.\"\n",
        "    \n",
        "\n",
        "# Practice using our new warning system\n",
        "check_size_of_boots(selected_harness_size=55, selected_boot_size=39)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "We've loaded a model with the following parameters:\nIntercept       5.719110\nharness_size    0.585925\ndtype: float64\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "'The boots you have selected might be TOO BIG for a dog as small as yours. We recommend a doggy boots size of 38.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {},
      "id": "06b77289"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Change `selected_harness_size` and `selected_boot_size` in the preceding example and re-run the cell to see this in action.\n",
        "\n",
        "## Summary\n",
        "\n",
        "Well done! We've put together a system that can predict if customers are buying doggy boots that may not fit their avalanche dog, based solely on the size of harness they're purchasing. \n",
        "\n",
        "In this exercise, we practiced:\n",
        "\n",
        "1. Creating basic models\n",
        "2. Training, then saving them to disk\n",
        "3. Loading them from disk\n",
        "4. Making predictions with them using new data sets"
      ],
      "metadata": {},
      "id": "511158a7"
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "conda-env-azureml_py38-py"
    },
    "kernelspec": {
      "name": "conda-env-azureml_py38-py",
      "language": "python",
      "display_name": "azureml_py38"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}